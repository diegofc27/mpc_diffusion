diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..59b8755 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,6 +1,6 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # miscdiff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..59b8755 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,6 +1,6 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodesdiff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..fed7761 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodesdiff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..e350cf0 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'fernandi'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..511e4ac 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,7 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics, step=self.step)
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..fc96675 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        wandb=wandb,
     )
 
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..511e4ac 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,7 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics, step=self.step)
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..fc96675 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        wandb=wandb,
     )
 
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..511e4ac 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,7 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics, step=self.step)
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..9367293 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        wandb=wandb,
     )
 
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..511e4ac 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,7 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics, step=self.step)
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..9367293 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        wandb=wandb,
     )
 
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..511e4ac 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,7 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics, step=self.step)
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c230fcd 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..12d9fd8 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,9 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics, step=self.step)
+                if self.step !=0:
+                    import pdb; pdb.set_trace()
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c230fcd 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c230fcd 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..3ab7606 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -51,6 +62,7 @@ def main(**deps):
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
+    import pdb; pdb.set_trace()
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +152,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +163,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..6580d14 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -40,7 +40,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,8 +95,8 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..34f49f4 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = context_len
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..24cf542 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, Skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..da5ac6b 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+             self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..6580d14 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -40,7 +40,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,8 +95,8 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..019fd26 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..24cf542 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, Skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..da5ac6b 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+             self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..71d6d8b 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -40,7 +40,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +95,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..019fd26 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..24cf542 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, Skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..da5ac6b 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+             self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..71d6d8b 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -40,7 +40,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +95,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..019fd26 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..24cf542 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, Skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..7be4bf4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..71d6d8b 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -40,7 +40,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +95,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..019fd26 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..4b19b62 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..1f2b629 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..4db3f02 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -3,7 +3,8 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import gymnasium as gym
+import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
@@ -40,7 +41,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +96,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..019fd26 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..4b19b62 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..1f2b629 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..481cf35 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -57,3 +57,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..4db3f02 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -3,7 +3,8 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import gymnasium as gym
+import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
@@ -40,7 +41,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +96,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..106589e 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..4b19b62 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..1f2b629 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..6b3bd0e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,6 +21,17 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..f27f6c2 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,6 +20,7 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
@@ -57,3 +58,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..4db3f02 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -3,7 +3,8 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import gymnasium as gym
+import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
@@ -40,7 +41,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +96,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..106589e 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..4b19b62 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..1f2b629 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..2ed3a8e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,10 +21,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..f27f6c2 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,6 +20,7 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
@@ -57,3 +58,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..4db3f02 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -3,7 +3,8 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import gymnasium as gym
+import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
@@ -40,7 +41,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +96,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..106589e 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..4b19b62 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..1f2b629 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..2ed3a8e 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,6 +1,6 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
@@ -21,10 +21,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..c04833d 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..f27f6c2 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,6 +20,7 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
@@ -57,3 +58,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'hopper-medium-expert-v2'
+    wandb_tags = ['hopper-medium-expert-v2', 'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..574973c 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..4db3f02 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -3,7 +3,8 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import gymnasium as gym
+import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
@@ -40,7 +41,14 @@ def load_environment(name):
     return env
 
 def get_dataset(env):
-    dataset = env.get_dataset()
+    if(env.unwrapped.spec.id=='PandaPush-v3'):
+        with open('/home/fernandi/projects/decision-diffuser/code/skills/push_slide.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+            print("loaded pickle")
+    else:
+        dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -88,7 +96,7 @@ def sequence_dataset(env, preprocess_fn):
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
+        #if done_bool:        
         if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..106589e 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,7 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,6 +27,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
+        self.include_skills = include_skills
         itr = sequence_dataset(env, self.preprocess_fn)
 
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
@@ -101,6 +103,32 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1,0],[0,1]]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.normed_actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end]
+            one_hot_skills = np.array([one_hot[i] for i in skills])
+            skills = self.fields.skills[path_ind, start:end]
+            batch = Skills(trajectories, conditions, one_hot_skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..3a74b25 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,7 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..4b19b62 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -421,16 +421,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +442,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +457,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +466,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -625,7 +625,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +633,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +691,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +703,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..1f2b629 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -155,6 +155,16 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +206,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +227,15 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -268,6 +286,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +328,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +350,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +366,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +387,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +406,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..b724677 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -56,6 +56,7 @@ class Trainer(object):
         bucket=None,
         train_device='cuda',
         save_checkpoints=False,
+        wandb = None,
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,7 +64,7 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
@@ -132,6 +133,8 @@ class Trainer(object):
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
             if self.step == 0 and self.sample_freq:
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..f58c413 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,10 +1,10 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    import pdb; pdb.set_trace()
     RUN._update(deps)
     Config._update(deps)
 
@@ -21,10 +21,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+
+    # wandb.init(
+    # # set the wandb project where this run will be logged
+    #     project=Config.wandb_project,
+    #     entity=Config.wandb_entity,
+    #     group=Config.wandb_group,
+    #     name=Config.wandb_name,
+    #     # track hyperparameters and run metadata
+    #     config=Config.__dict__
+    # )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -140,6 +151,7 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +162,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    #trainer = trainer_config(diffusion, dataset, renderer,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,6 +175,7 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('✓')
+    import pdb; pdb.set_trace()
 
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#