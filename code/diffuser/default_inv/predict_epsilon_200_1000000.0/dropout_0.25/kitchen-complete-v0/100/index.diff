diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..362e8a8 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -2,11 +2,17 @@ if __name__ == '__main__':
     from ml_logger import logger, instr, needs_relaunch
     from analysis import RUN
     import jaynes
-    from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/push_dense_100k_1seed.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..3c43c1a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -3,12 +3,15 @@ import collections
 import numpy as np
 import gym
 import pdb
-
+import gymnasium as gym
+import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +23,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +35,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +44,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +69,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +84,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..5e2af63 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..9f4a039 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            if self.step % self.test_freq == 0:
+                success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+                log = {}
+                log["success_rate"]  = success_rate
+                log["rewards"] = rewards
+                self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
             if self.sample_freq and self.step % self.sample_freq == 0:
                 if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
                     self.inv_render_samples()
                 elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
                     pass
-                else:
-                    self.render_samples()
+                # else:
+                #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..bc8f230 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..362e8a8 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -2,11 +2,17 @@ if __name__ == '__main__':
     from ml_logger import logger, instr, needs_relaunch
     from analysis import RUN
     import jaynes
-    from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/push_dense_100k_1seed.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..5e2af63 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..9f4a039 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            if self.step % self.test_freq == 0:
+                success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+                log = {}
+                log["success_rate"]  = success_rate
+                log["rewards"] = rewards
+                self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
             if self.sample_freq and self.step % self.sample_freq == 0:
                 if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
                     self.inv_render_samples()
                 elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
                     pass
-                else:
-                    self.render_samples()
+                # else:
+                #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..bc8f230 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..362e8a8 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -2,11 +2,17 @@ if __name__ == '__main__':
     from ml_logger import logger, instr, needs_relaunch
     from analysis import RUN
     import jaynes
-    from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/push_dense_100k_1seed.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..9f4a039 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            if self.step % self.test_freq == 0:
+                success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+                log = {}
+                log["success_rate"]  = success_rate
+                log["rewards"] = rewards
+                self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
             if self.sample_freq and self.step % self.sample_freq == 0:
                 if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
                     self.inv_render_samples()
                 elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
                     pass
-                else:
-                    self.render_samples()
+                # else:
+                #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..bc8f230 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..362e8a8 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -2,11 +2,17 @@ if __name__ == '__main__':
     from ml_logger import logger, instr, needs_relaunch
     from analysis import RUN
     import jaynes
-    from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/push_dense_100k_1seed.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..ce89828 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
             if self.sample_freq and self.step % self.sample_freq == 0:
                 if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
                     self.inv_render_samples()
                 elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
                     pass
-                else:
-                    self.render_samples()
+                # else:
+                #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..bc8f230 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..362e8a8 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -2,11 +2,17 @@ if __name__ == '__main__':
     from ml_logger import logger, instr, needs_relaunch
     from analysis import RUN
     import jaynes
-    from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/push_dense_100k_1seed.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..bc8f230 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..362e8a8 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -2,11 +2,17 @@ if __name__ == '__main__':
     from ml_logger import logger, instr, needs_relaunch
     from analysis import RUN
     import jaynes
-    from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/analysis/push_dense_100k_1seed.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..bc8f230 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..355fedf 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..9744802 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -216,8 +279,26 @@ class TemporalUnet(nn.Module):
                 returns_embed = mask*returns_embed
             if force_dropout:
                 returns_embed = 0*returns_embed
+            import pdb; pdb.set_trace()
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +311,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +380,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +571,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +613,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +635,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +651,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +672,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +691,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..42aa310 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,7 +454,7 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..590a1b1 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -442,13 +454,13 @@ class GaussianInvDynDiffusion(nn.Module):
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
+        import pdb; pdb.set_trace()
         progress.close()
 
         if return_diffusion:
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..d0cec03 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -438,17 +450,17 @@ class GaussianInvDynDiffusion(nn.Module):
         x = apply_conditioning(x, cond, 0)
 
         if return_diffusion: diffusion = [x]
-
+        import pdb; pdb.set_trace()
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
+        import pdb; pdb.set_trace()
         progress.close()
 
         if return_diffusion:
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..d0cec03 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -438,17 +450,17 @@ class GaussianInvDynDiffusion(nn.Module):
         x = apply_conditioning(x, cond, 0)
 
         if return_diffusion: diffusion = [x]
-
+        import pdb; pdb.set_trace()
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
+        import pdb; pdb.set_trace()
         progress.close()
 
         if return_diffusion:
@@ -457,7 +469,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +478,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +492,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +512,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +531,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +552,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +908,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +916,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +974,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +986,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..43d753a 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,13 +156,13 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
-        obs_list = []
+        # obs_list = []
         for i in range(num_eval):
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..b0b4c2c 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -438,17 +450,15 @@ class GaussianInvDynDiffusion(nn.Module):
         x = apply_conditioning(x, cond, 0)
 
         if return_diffusion: diffusion = [x]
-
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
         progress.close()
 
         if return_diffusion:
@@ -457,7 +467,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +476,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +490,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +510,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +529,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +550,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +906,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +914,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +972,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +984,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..a73daa5 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,11 +156,11 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
         obs_list = []
         for i in range(num_eval):
@@ -183,9 +184,9 @@ def evaluate(**deps):
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..b0b4c2c 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -438,17 +450,15 @@ class GaussianInvDynDiffusion(nn.Module):
         x = apply_conditioning(x, cond, 0)
 
         if return_diffusion: diffusion = [x]
-
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
         progress.close()
 
         if return_diffusion:
@@ -457,7 +467,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +476,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +490,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +510,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +529,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +550,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +906,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +914,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +972,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +984,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..af2f720 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,11 +156,11 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
         obs_list = []
         for i in range(num_eval):
@@ -180,12 +181,15 @@ def evaluate(**deps):
 
         obs = np.concatenate(obs_list, axis=0)
         recorded_obs.append(deepcopy(obs[:, None]))
+        print(f"t: {t}, episode_rewards: {episode_rewards}, dones: {dones}")
+        if t> 200:
+            break
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..b0b4c2c 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -438,17 +450,15 @@ class GaussianInvDynDiffusion(nn.Module):
         x = apply_conditioning(x, cond, 0)
 
         if return_diffusion: diffusion = [x]
-
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
         progress.close()
 
         if return_diffusion:
@@ -457,7 +467,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +476,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +490,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +510,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +529,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +550,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +906,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +914,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +972,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +984,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..79a1678 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,15 +156,15 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
         obs_list = []
         for i in range(num_eval):
-            this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
+            this_obs, this_reward, this_done, _ = env_list[i].step([action[i]])
             obs_list.append(this_obs[None])
             if this_done:
                 if dones[i] == 1:
@@ -180,12 +181,15 @@ def evaluate(**deps):
 
         obs = np.concatenate(obs_list, axis=0)
         recorded_obs.append(deepcopy(obs[:, None]))
+        print(f"t: {t}, episode_rewards: {episode_rewards}, dones: {dones}")
+        if t> 200:
+            break
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#diff --git a/code/analysis/__init__.py b/code/analysis/__init__.py
index 0ca683a..3b8b704 100644
--- a/code/analysis/__init__.py
+++ b/code/analysis/__init__.py
@@ -1,5 +1,4 @@
 from os.path import dirname, join
-
 from ml_logger import RUN, instr
 from termcolor import colored
 
diff --git a/code/analysis/default_inv.py b/code/analysis/default_inv.py
index ec2dc3f..7176898 100644
--- a/code/analysis/default_inv.py
+++ b/code/analysis/default_inv.py
@@ -1,6 +1,6 @@
 from pathlib import Path
 
-from params_proto.neo_hyper import Sweep
+from params_proto.hyper import Sweep
 
 from config.locomotion_config import Config
 from analysis import RUN
@@ -16,7 +16,7 @@ with Sweep(RUN, Config) as sweep:
 
     with sweep.product:
         Config.n_train_steps = [1e6]
-        Config.dataset = ['hopper-medium-expert-v2']
+        Config.dataset = ['kitchen-complete-v0']
         Config.returns_scale = [400.0]
 
 @sweep.each
diff --git a/code/analysis/eval.py b/code/analysis/eval.py
index 87445df..5380a5b 100644
--- a/code/analysis/eval.py
+++ b/code/analysis/eval.py
@@ -3,10 +3,16 @@ if __name__ == '__main__':
     from analysis import RUN
     import jaynes
     from scripts.evaluate_inv_parallel import evaluate
+    #from scripts.evaluate_skills import evaluate
+    
+    #from scripts.evaluate_skills_parallel import evaluate
+    #from scripts.evaluate_panda_parallel_script import evaluate
+    #from scripts.eval_point import evaluate
+    #from scripts.find_composition_w import evaluate
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +20,4 @@ if __name__ == '__main__':
         thunk = instr(evaluate, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
\ No newline at end of file
+    # jaynes.listen()
\ No newline at end of file
diff --git a/code/analysis/train.py b/code/analysis/train.py
index a1dad1d..216d5c4 100644
--- a/code/analysis/train.py
+++ b/code/analysis/train.py
@@ -4,9 +4,9 @@ if __name__ == '__main__':
     import jaynes
     from scripts.train import main
     from config.locomotion_config import Config
-    from params_proto.neo_hyper import Sweep
+    from params_proto.hyper import Sweep
 
-    sweep = Sweep(RUN, Config).load("default_inv.jsonl")
+    sweep = Sweep(RUN, Config).load("/home/fernandi/projects/decision-diffuser/code/default_inv.jsonl")
 
     for kwargs in sweep:
         logger.print(RUN.prefix, color='green')
@@ -14,4 +14,4 @@ if __name__ == '__main__':
         thunk = instr(main, **kwargs)
         jaynes.run(thunk)
 
-    jaynes.listen()
+    # jaynes.listen()
diff --git a/code/config/locomotion_config.py b/code/config/locomotion_config.py
index 90173b3..46c3c53 100644
--- a/code/config/locomotion_config.py
+++ b/code/config/locomotion_config.py
@@ -1,12 +1,12 @@
 import torch
 
-from params_proto.neo_proto import ParamsProto, PrefixProto, Proto
+from params_proto import ParamsProto, PrefixProto, Proto
 
 class Config(ParamsProto):
     # misc
     seed = 100
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    bucket = '/home/aajay/weights/'
+    device = 'cuda:6' #torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    bucket = '/home/fernandi/projects/decision-diffuser/code/weights/'
     dataset = 'hopper-medium-expert-v2'
 
     ## model
@@ -20,12 +20,15 @@ class Config(ParamsProto):
     predict_epsilon = True
     dim_mults = (1, 4, 8)
     returns_condition = True
+    skills_condition = False
+    goal_condition = False
     calc_energy=False
     dim=128
     condition_dropout=0.25
     condition_guidance_w = 1.2
     test_ret=0.9
     renderer = 'utils.MuJoCoRenderer'
+    attention = False
 
     ## dataset
     loader = 'datasets.SequenceDataset'
@@ -41,6 +44,9 @@ class Config(ParamsProto):
     train_only_inv = False
     termination_penalty = -100
     returns_scale = 400.0 # Determined using rewards from the dataset
+    max_n_episodes = 1000000
+    point_dataset = 'xy_dataset_20'
+    skill_dataset = 'xy_dataset_20'
 
     ## training
     n_steps_per_epoch = 10000
@@ -57,3 +63,10 @@ class Config(ParamsProto):
     save_parallel = False
     n_reference = 8
     save_checkpoints = False
+
+    #wandb
+    wandb_project = 'decision-diffuser'
+    wandb_entity = 'diegofc'
+    wandb_group = 'PandaPush-v3'
+    wandb_tags = [  'decision-diffuser']
+    wandb_name = "test"
\ No newline at end of file
diff --git a/code/diffuser/datasets/buffer.py b/code/diffuser/datasets/buffer.py
index 42bc734..0e4ebc8 100644
--- a/code/diffuser/datasets/buffer.py
+++ b/code/diffuser/datasets/buffer.py
@@ -9,7 +9,7 @@ class ReplayBuffer:
 
     def __init__(self, max_n_episodes, max_path_length, termination_penalty):
         self._dict = {
-            'path_lengths': np.zeros(max_n_episodes, dtype=np.int),
+            'path_lengths': np.zeros(max_n_episodes, dtype=int),
         }
         self._count = 0
         self.max_n_episodes = max_n_episodes
@@ -62,8 +62,8 @@ class ReplayBuffer:
         # print(f'[ utils/mujoco ] Allocated {key} with size {shape}')
 
     def add_path(self, path):
-        path_length = len(path['observations'])
-        assert path_length <= self.max_path_length
+        path_length = len(path['observations'])    
+        assert path_length <= self.max_path_length, f'Path length {path_length} exceeds max path length {self.max_path_length}'
 
         if path['terminals'].any():
             assert (path['terminals'][-1] == True) and (not path['terminals'][:-1].any())
@@ -75,11 +75,13 @@ class ReplayBuffer:
         for key in self.keys:
             array = atleast_2d(path[key])
             if key not in self._dict: self._allocate(key, array)
+            if key == 'infos':
+                continue
             self._dict[key][self._count, :path_length] = array
 
         ## penalize early termination
         if path['terminals'].any() and self.termination_penalty is not None:
-            assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
+            #assert not path['timeouts'].any(), 'Penalized a timeout episode for early termination'
             self._dict['rewards'][self._count, path_length - 1] += self.termination_penalty
 
         ## record path length
diff --git a/code/diffuser/datasets/d4rl.py b/code/diffuser/datasets/d4rl.py
index 8ade6a0..8275a2a 100644
--- a/code/diffuser/datasets/d4rl.py
+++ b/code/diffuser/datasets/d4rl.py
@@ -2,13 +2,17 @@ import os
 import collections
 import numpy as np
 import gym
+import d4rl
 import pdb
-
+# import gymnasium as gym
+# import panda_gym
 from contextlib import (
     contextmanager,
     redirect_stderr,
     redirect_stdout,
 )
+import pickle
+from diffuser.environments.point import Find_Dot
 
 @contextmanager
 def suppress_output():
@@ -20,9 +24,9 @@ def suppress_output():
         with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:
             yield (err, out)
 
-with suppress_output():
-    ## d4rl prints out a variety of warnings
-    import d4rl
+# with suppress_output():
+#     ## d4rl prints out a variety of warnings
+#     import d4rl
 
 #-----------------------------------------------------------------------------#
 #-------------------------------- general api --------------------------------#
@@ -32,6 +36,8 @@ def load_environment(name):
     if type(name) != str:
         ## name is already an environment
         return name
+    if name == 'FindDot-v0':
+        return Find_Dot(max_number_steps=20)
     with suppress_output():
         wrapped_env = gym.make(name)
     env = wrapped_env.unwrapped
@@ -39,8 +45,20 @@ def load_environment(name):
     env.name = name
     return env
 
-def get_dataset(env):
-    dataset = env.get_dataset()
+def get_dataset(env,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
+    if(env.__class__.__name__=='Find_Dot'):
+        print(f"Using pickle: {point_dataset}")
+        with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{point_dataset}.pickle', 'rb') as handle:
+            dataset = pickle.load(handle)
+    else:
+        if(env.unwrapped.spec.id=='PandaPushDense-v3'):
+            with open(f'/home/fernandi/projects/decision-diffuser/code/skills/{skill_dataset}.pickle', 'rb') as handle:
+                dataset = pickle.load(handle)
+                print("loaded pickle")
+        else:
+            dataset = env.get_dataset()
+    print("episodes")
+    print((dataset['terminals']==True).sum())
 
     if 'antmaze' in str(env).lower():
         ## the antmaze-v0 environments have a variety of bugs
@@ -52,7 +70,7 @@ def get_dataset(env):
 
     return dataset
 
-def sequence_dataset(env, preprocess_fn):
+def sequence_dataset(env, preprocess_fn,point_dataset="xy_dataset_20",skill_dataset="PandaPushDense-v3_single_seed_test_123"):
     """
     Returns an iterator through trajectories.
     Args:
@@ -67,29 +85,27 @@ def sequence_dataset(env, preprocess_fn):
             rewards
             terminals
     """
-    dataset = get_dataset(env)
+    dataset = get_dataset(env,point_dataset,skill_dataset)
     dataset = preprocess_fn(dataset)
-
     N = dataset['rewards'].shape[0]
     data_ = collections.defaultdict(list)
 
     # The newer version of the dataset adds an explicit
     # timeouts field. Keep old method for backwards compatability.
     use_timeouts = 'timeouts' in dataset
-
     episode_step = 0
     for i in range(N):
         done_bool = bool(dataset['terminals'][i])
         if use_timeouts:
             final_timestep = dataset['timeouts'][i]
         else:
-            final_timestep = (episode_step == env._max_episode_steps - 1)
-
+            #final_timestep = (episode_step == env._max_episode_steps - 1)
+            final_timestep = (episode_step == env.max_episode_steps - 1)
         for k in dataset:
             if 'metadata' in k: continue
             data_[k].append(dataset[k][i])
-
-        if done_bool or final_timestep:
+        if done_bool:        
+        #if done_bool or final_timestep:
             episode_step = 0
             episode_data = {}
             for k in data_:
diff --git a/code/diffuser/datasets/normalization.py b/code/diffuser/datasets/normalization.py
index 34db077..bf487f9 100644
--- a/code/diffuser/datasets/normalization.py
+++ b/code/diffuser/datasets/normalization.py
@@ -269,13 +269,13 @@ class CDFNormalizer1d:
 
         x = (x + 1) / 2.
 
-        if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
-            print(
-                f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
-                f'''[{x.min()}, {x.max()}] | '''
-                f'''x : [{self.xmin}, {self.xmax}] | '''
-                f'''y: [{self.ymin}, {self.ymax}]'''
-            )
+        # if (x < self.ymin - eps).any() or (x > self.ymax + eps).any():
+        #     print(
+        #         f'''[ dataset/normalization ] Warning: out of range in unnormalize: '''
+        #         f'''[{x.min()}, {x.max()}] | '''
+        #         f'''x : [{self.xmin}, {self.xmax}] | '''
+        #         f'''y: [{self.ymin}, {self.ymax}]'''
+        #     )
 
         x = np.clip(x, self.ymin, self.ymax)
 
diff --git a/code/diffuser/datasets/sequence.py b/code/diffuser/datasets/sequence.py
index 31ac84f..065ceb5 100644
--- a/code/diffuser/datasets/sequence.py
+++ b/code/diffuser/datasets/sequence.py
@@ -9,6 +9,7 @@ from .normalization import DatasetNormalizer
 from .buffer import ReplayBuffer
 
 RewardBatch = namedtuple('Batch', 'trajectories conditions returns')
+SkillBatch = namedtuple('Batch', 'trajectories conditions skills')
 Batch = namedtuple('Batch', 'trajectories conditions')
 ValueBatch = namedtuple('ValueBatch', 'trajectories conditions values')
 
@@ -16,7 +17,8 @@ class SequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
         normalizer='LimitsNormalizer', preprocess_fns=[], max_path_length=1000,
-        max_n_episodes=10000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False):
+        max_n_episodes=1000000, termination_penalty=0, use_padding=True, discount=0.99, returns_scale=1000, include_returns=False,include_skills=False, 
+        point_dataset=None,skill_dataset=None):
         self.preprocess_fn = get_preprocess_fn(preprocess_fns, env)
         self.env = env = load_environment(env)
         self.returns_scale = returns_scale
@@ -26,8 +28,8 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.discounts = self.discount ** np.arange(self.max_path_length)[:, None]
         self.use_padding = use_padding
         self.include_returns = include_returns
-        itr = sequence_dataset(env, self.preprocess_fn)
-
+        self.include_skills = include_skills
+        itr = sequence_dataset(env, self.preprocess_fn,point_dataset,skill_dataset)
         fields = ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)
         for i, episode in enumerate(itr):
             fields.add_path(episode)
@@ -42,7 +44,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.n_episodes = fields.n_episodes
         self.path_lengths = fields.path_lengths
         self.normalize()
-
         print(fields)
         # shapes = {key: val.shape for key, val in self.fields.items()}
         # print(f'[ datasets/mujoco ] Dataset fields: {shapes}')
@@ -101,6 +102,55 @@ class SequenceDataset(torch.utils.data.Dataset):
 
         return batch
 
+
+class SkillsDataset(SequenceDataset):
+
+    def __init__(self, *args, include_skills=True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.include_skills = include_skills
+        self.one_hot = [[1.0,0.0],[0.0,1.0]]
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+
+        if self.include_skills:
+            skills = self.fields.skills[path_ind, start:end][0]
+            batch = SkillBatch(trajectories, conditions, skills)
+        else:
+            batch = Batch(trajectories, conditions)
+
+        return batch
+    
+class GoalsDataset(SequenceDataset):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def get_one_hot(self, skill):
+        return self.one_hot[skill]
+
+    def __getitem__(self, idx, eps=1e-4):
+        path_ind, start, end = self.indices[idx]
+
+        observations = self.fields.normed_observations[path_ind, start:end]
+        actions = self.fields.actions[path_ind, start:end]
+        conditions = self.get_conditions(observations)
+        trajectories = np.concatenate([actions, observations], axis=-1)
+        goal = observations[0][18:21]
+        batch = SkillBatch(trajectories, conditions, goal)
+        
+
+        return batch
+
+
 class CondSequenceDataset(torch.utils.data.Dataset):
 
     def __init__(self, env='hopper-medium-replay', horizon=64,
diff --git a/code/diffuser/environments/__init__.py b/code/diffuser/environments/__init__.py
index 455bcf3..625695d 100644
--- a/code/diffuser/environments/__init__.py
+++ b/code/diffuser/environments/__init__.py
@@ -1,3 +1,3 @@
+# from .point import Find_Dot
 from .registration import register_environments
-
 registered_environments = register_environments()
\ No newline at end of file
diff --git a/code/diffuser/environments/registration.py b/code/diffuser/environments/registration.py
index 655a6f0..d033384 100644
--- a/code/diffuser/environments/registration.py
+++ b/code/diffuser/environments/registration.py
@@ -17,6 +17,11 @@ ENVIRONMENT_SPECS = (
         'id': 'AntFullObs-v2',
         'entry_point': ('diffuser.environments.ant:AntFullObsEnv'),
     },
+    {
+        'id': 'FindDot-v0',
+        'entry_point': ('diffuser.environments.point:Find_Dot'),
+    }
+
 )
 
 def register_environments():
diff --git a/code/diffuser/models/__init__.py b/code/diffuser/models/__init__.py
index 7695359..c5e4036 100644
--- a/code/diffuser/models/__init__.py
+++ b/code/diffuser/models/__init__.py
@@ -1,2 +1,2 @@
 from .temporal import TemporalUnet, TemporalValue, MLPnet
-from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion
\ No newline at end of file
+from .diffusion import GaussianDiffusion, ActionGaussianDiffusion, GaussianInvDynDiffusion,GaussianInvDynDiffusionSkills
\ No newline at end of file
diff --git a/code/diffuser/models/diffusion.py b/code/diffuser/models/diffusion.py
index a1f74ea..b0b4c2c 100644
--- a/code/diffuser/models/diffusion.py
+++ b/code/diffuser/models/diffusion.py
@@ -12,6 +12,12 @@ from .helpers import (
     Losses,
 )
 
+def discountMatrix(rows,cols,discount=0.98):
+    matrix = torch.zeros(rows, cols)
+    for i in range(rows):
+        matrix[i, :] = torch.pow(torch.tensor(discount), i)
+    return matrix
+
 class GaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
@@ -292,7 +298,7 @@ class GaussianInvDynDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False):
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
         super().__init__()
         self.horizon = horizon
         self.observation_dim = observation_dim
@@ -313,6 +319,7 @@ class GaussianInvDynDiffusion(nn.Module):
             )
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -399,12 +406,17 @@ class GaussianInvDynDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.returns_condition:
             # epsilon could be epsilon or x0 itself
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skills_condition:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
@@ -421,16 +433,16 @@ class GaussianInvDynDiffusion(nn.Module):
         return model_mean, posterior_variance, posterior_log_variance
 
     @torch.no_grad()
-    def p_sample(self, x, cond, t, returns=None):
+    def p_sample(self, x, cond, t, returns=None,skills=None):
         b, *_, device = *x.shape, x.device
-        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns)
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, returns=returns,skills=skills)
         noise = 0.5*torch.randn_like(x)
         # no noise when t == 0
         nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
         return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
 
     @torch.no_grad()
-    def p_sample_loop(self, shape, cond, returns=None, verbose=True, return_diffusion=False):
+    def p_sample_loop(self, shape, cond, returns=None, skills =None, verbose=True, return_diffusion=False):
         device = self.betas.device
 
         batch_size = shape[0]
@@ -438,17 +450,15 @@ class GaussianInvDynDiffusion(nn.Module):
         x = apply_conditioning(x, cond, 0)
 
         if return_diffusion: diffusion = [x]
-
         progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
         for i in reversed(range(0, self.n_timesteps)):
             timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
-            x = self.p_sample(x, cond, timesteps, returns)
+            x = self.p_sample(x, cond, timesteps, returns,skills)
             x = apply_conditioning(x, cond, 0)
 
             progress.update({'t': i})
 
             if return_diffusion: diffusion.append(x)
-
         progress.close()
 
         if return_diffusion:
@@ -457,7 +467,7 @@ class GaussianInvDynDiffusion(nn.Module):
             return x
 
     @torch.no_grad()
-    def conditional_sample(self, cond, returns=None, horizon=None, *args, **kwargs):
+    def conditional_sample(self, cond, returns=None, skills=None, horizon=None, *args, **kwargs):
         '''
             conditions : [ (time, state), ... ]
         '''
@@ -466,7 +476,7 @@ class GaussianInvDynDiffusion(nn.Module):
         horizon = horizon or self.horizon
         shape = (batch_size, horizon, self.observation_dim)
 
-        return self.p_sample_loop(shape, cond, returns, *args, **kwargs)
+        return self.p_sample_loop(shape, cond, returns, skills, *args, **kwargs)
     #------------------------------------------ training ------------------------------------------#
 
     def q_sample(self, x_start, t, noise=None):
@@ -480,13 +490,13 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return sample
 
-    def p_losses(self, x_start, cond, t, returns=None):
+    def p_losses(self, x_start, cond, t, returns=None, skills=None):
         noise = torch.randn_like(x_start)
 
         x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
         x_noisy = apply_conditioning(x_noisy, cond, 0)
 
-        x_recon = self.model(x_noisy, cond, t, returns)
+        x_recon = self.model(x_noisy, cond, t, returns, skills)
 
         if not self.predict_epsilon:
             x_recon = apply_conditioning(x_recon, cond, 0)
@@ -500,7 +510,7 @@ class GaussianInvDynDiffusion(nn.Module):
 
         return loss, info
 
-    def loss(self, x, cond, returns=None):
+    def loss(self, x, cond, returns=None,skills=None):
         if self.train_only_inv:
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
@@ -519,7 +529,7 @@ class GaussianInvDynDiffusion(nn.Module):
         else:
             batch_size = len(x)
             t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
-            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns)
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t, returns,skills)
             # Calculating inv loss
             x_t = x[:, :-1, self.action_dim:]
             a_t = x[:, :-1, :self.action_dim]
@@ -540,6 +550,277 @@ class GaussianInvDynDiffusion(nn.Module):
     def forward(self, cond, *args, **kwargs):
         return self.conditional_sample(cond=cond, *args, **kwargs)
 
+class GaussianInvDynDiffusionSkills(nn.Module):
+    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
+        loss_type='l1', clip_denoised=False, predict_epsilon=True, hidden_dim=256,
+        action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False, discount=0.99,
+        condition_guidance_w=0.1, ar_inv=False, train_only_inv=False,skills_condition=False,goal_condition=False):
+        super().__init__()
+        self.horizon = horizon
+        self.observation_dim = observation_dim
+        self.action_dim = action_dim
+        self.transition_dim = observation_dim + action_dim
+        self.model = model
+        self.ar_inv = ar_inv
+        self.train_only_inv = train_only_inv
+        self.action_weight = action_weight
+        self.discount = discount
+        if self.ar_inv:
+            self.inv_model = ARInvModel(hidden_dim=hidden_dim, observation_dim=observation_dim, action_dim=action_dim)
+        else:
+            self.inv_model = nn.Sequential(
+                nn.Linear(2 * self.observation_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, hidden_dim),
+                nn.ReLU(),
+                nn.Linear(hidden_dim, self.action_dim),
+            )
+        self.returns_condition = False
+        self.condition_guidance_w = condition_guidance_w
+        self.skills_condition = skills_condition
+        self.goal_condition = goal_condition
+
+        betas = cosine_beta_schedule(n_timesteps)
+        alphas = 1. - betas
+        alphas_cumprod = torch.cumprod(alphas, axis=0)
+        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])
+
+        self.n_timesteps = int(n_timesteps)
+        self.clip_denoised = clip_denoised
+        self.predict_epsilon = predict_epsilon
+
+        self.register_buffer('betas', betas)
+        self.register_buffer('alphas_cumprod', alphas_cumprod)
+        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
+
+        # calculations for diffusion q(x_t | x_{t-1}) and others
+        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
+        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
+        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))
+        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))
+        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))
+
+        # calculations for posterior q(x_{t-1} | x_t, x_0)
+        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)
+        self.register_buffer('posterior_variance', posterior_variance)
+
+        ## log calculation clipped because the posterior variance
+        ## is 0 at the beginning of the diffusion chain
+        self.register_buffer('posterior_log_variance_clipped',
+            torch.log(torch.clamp(posterior_variance, min=1e-20)))
+        self.register_buffer('posterior_mean_coef1',
+            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))
+        self.register_buffer('posterior_mean_coef2',
+            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))
+
+        ## get loss coefficients and initialize objective
+        loss_weights = self.get_loss_weights(loss_discount)
+        self.loss_fn = Losses['state_l2'](loss_weights)
+
+    def get_loss_weights(self, discount):
+        '''
+            sets loss coefficients for trajectory
+
+            action_weight   : float
+                coefficient on first action loss
+            discount   : float
+                multiplies t^th timestep of trajectory loss by discount**t
+            weights_dict    : dict
+                { i: c } multiplies dimension i of observation loss by c
+        '''
+        dim_weights = torch.ones(self.observation_dim, dtype=torch.float32)
+
+        ## decay loss with trajectory timestep: discount**t
+        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)
+        discounts = discounts / discounts.mean()
+        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)
+        
+        loss_weights= discountMatrix(loss_weights.shape[0], loss_weights.shape[1], discount)
+        # Cause things are conditioned on t=0
+        if self.predict_epsilon:
+            loss_weights[0, :] = 0
+        loss_weights[1,:] =self.action_weight
+
+        return loss_weights
+
+    #------------------------------------------ sampling ------------------------------------------#
+
+    def predict_start_from_noise(self, x_t, t, noise):
+        '''
+            if self.predict_epsilon, model output is (scaled) noise;
+            otherwise, model predicts x0 directly
+        '''
+        if self.predict_epsilon:
+            return (
+                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
+                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
+            )
+        else:
+            return noise
+
+    def q_posterior(self, x_start, x_t, t):
+        posterior_mean = (
+            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
+            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
+        )
+        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
+        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
+        return posterior_mean, posterior_variance, posterior_log_variance_clipped
+
+    def p_mean_variance(self, x, cond, t, skills):
+        if self.skills_condition:
+            # if skills.shape[0] ==1:
+            # epsilon could be epsilon or x0 itself
+            epsilon_cond = self.model(x, cond, t, skills=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+            # else:
+            #     delta_acc = 0
+            #     epsilon_uncond = self.model(x, cond, t, skills=skills[0].unsqueeze(0), force_dropout=True)
+            #     for i in range(skills.shape[0]):
+            #         epsilon_cond = self.model(x, cond, t, skills=skills[i].unsqueeze(0), use_dropout=False)
+            #         delta_acc +=self.condition_guidance_w[i]*(epsilon_cond - epsilon_uncond)
+            #     epsilon = epsilon_uncond + delta_acc
+        elif self.goal_condition:
+            epsilon_cond = self.model(x, cond, t, goals=skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, goals=skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        else:
+            epsilon = self.model(x, cond, t)
+
+        t = t.detach().to(torch.int64)
+        x_recon = self.predict_start_from_noise(x, t=t, noise=epsilon)
+
+        if self.clip_denoised:
+            x_recon.clamp_(-1., 1.)
+        else:
+            assert RuntimeError()
+
+        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(
+                x_start=x_recon, x_t=x, t=t)
+        return model_mean, posterior_variance, posterior_log_variance
+
+    @torch.no_grad()
+    def p_sample(self, x, cond, t,skills):
+        b, *_, device = *x.shape, x.device
+        model_mean, _, model_log_variance = self.p_mean_variance(x=x, cond=cond, t=t, skills=skills)
+        noise = 0.5*torch.randn_like(x)
+        # no noise when t == 0
+        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))
+        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise
+
+    @torch.no_grad()
+    def p_sample_loop(self, shape, cond, skills, verbose=True, return_diffusion=False):
+        device = self.betas.device
+
+        batch_size = shape[0]
+        x = 0.5*torch.randn(shape, device=device)
+        x = apply_conditioning(x, cond, 0)
+
+        if return_diffusion: diffusion = [x]
+
+        progress = utils.Progress(self.n_timesteps) if verbose else utils.Silent()
+        for i in reversed(range(0, self.n_timesteps)):
+            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)
+            x = self.p_sample(x, cond, timesteps,skills)
+            x = apply_conditioning(x, cond, 0)
+
+            progress.update({'t': i})
+
+            if return_diffusion: diffusion.append(x)
+
+        progress.close()
+
+        if return_diffusion:
+            return x, torch.stack(diffusion, dim=1)
+        else:
+            return x
+
+    @torch.no_grad()
+    def conditional_sample(self, cond, skills, horizon=None, *args, **kwargs):
+        '''
+            conditions : [ (time, state), ... ]
+        '''
+        device = self.betas.device
+        batch_size = len(cond[0])
+        horizon = horizon or self.horizon
+        shape = (batch_size, horizon, self.observation_dim)
+
+        return self.p_sample_loop(shape, cond, skills, *args, **kwargs)
+    #------------------------------------------ training ------------------------------------------#
+
+    def q_sample(self, x_start, t, noise=None):
+        if noise is None:
+            noise = torch.randn_like(x_start)
+
+        sample = (
+            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
+            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
+        )
+
+        return sample
+
+    def p_losses(self, x_start, cond, t, skills):
+        noise = torch.randn_like(x_start)
+
+        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)
+        x_noisy = apply_conditioning(x_noisy, cond, 0)
+        x_recon = self.model(x_noisy, cond, t, skills=skills)
+
+        if not self.predict_epsilon:
+            x_recon = apply_conditioning(x_recon, cond, 0)
+
+        assert noise.shape == x_recon.shape
+
+        if self.predict_epsilon:
+            loss, info = self.loss_fn(x_recon, noise)
+        else:
+            loss, info = self.loss_fn(x_recon, x_start)
+
+        return loss, info
+
+    def loss(self, x, cond, skills=None):
+        if self.train_only_inv:
+            # Calculating inv loss
+
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            import pdb; pdb.set_trace()
+            if self.ar_inv:
+                loss = self.inv_model.calc_loss(x_comb_t, a_t)
+                info = {'a0_loss':loss}
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                loss = F.mse_loss(pred_a_t, a_t)
+                info = {'a0_loss': loss}
+        else:
+            batch_size = len(x)
+            t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()
+            diffuse_loss, info = self.p_losses(x[:, :, self.action_dim:], cond, t,skills)
+            # Calculating inv loss
+            x_t = x[:, :-1, self.action_dim:]
+            a_t = x[:, :-1, :self.action_dim]
+            x_t_1 = x[:, 1:, self.action_dim:]
+            x_comb_t = torch.cat([x_t, x_t_1], dim=-1)
+            x_comb_t = x_comb_t.reshape(-1, 2 * self.observation_dim)
+            a_t = a_t.reshape(-1, self.action_dim)
+            if self.ar_inv:
+                inv_loss = self.inv_model.calc_loss(x_comb_t, a_t)
+            else:
+                pred_a_t = self.inv_model(x_comb_t)
+                inv_loss = F.mse_loss(pred_a_t, a_t)
+
+            loss = (1 / 2) * (diffuse_loss + inv_loss)
+            info['inv_loss'] = inv_loss
+        return loss, info
+
+    def forward(self, cond, *args, **kwargs):
+        return self.conditional_sample(cond=cond, *args, **kwargs)
+
 
 class ARInvModel(nn.Module):
     def __init__(self, hidden_dim, observation_dim, action_dim, low_act=-1.0, up_act=1.0):
@@ -625,7 +906,7 @@ class ActionGaussianDiffusion(nn.Module):
     def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,
         loss_type='l1', clip_denoised=False, predict_epsilon=True,
         action_weight=1.0, loss_discount=1.0, loss_weights=None, returns_condition=False,
-        condition_guidance_w=0.1,):
+        condition_guidance_w=0.1,skill_condition=False,):
         super().__init__()
         self.observation_dim = observation_dim
         self.action_dim = action_dim
@@ -633,6 +914,7 @@ class ActionGaussianDiffusion(nn.Module):
         self.model = model
         self.returns_condition = returns_condition
         self.condition_guidance_w = condition_guidance_w
+        self.skill_condition    = skill_condition
 
         betas = cosine_beta_schedule(n_timesteps)
         alphas = 1. - betas
@@ -690,7 +972,7 @@ class ActionGaussianDiffusion(nn.Module):
         posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)
         return posterior_mean, posterior_variance, posterior_log_variance_clipped
 
-    def p_mean_variance(self, x, cond, t, returns=None):
+    def p_mean_variance(self, x, cond, t, returns=None, skills=None):
         if self.model.calc_energy:
             assert self.predict_epsilon
             x = torch.tensor(x, requires_grad=True)
@@ -702,6 +984,10 @@ class ActionGaussianDiffusion(nn.Module):
             epsilon_cond = self.model(x, cond, t, returns, use_dropout=False)
             epsilon_uncond = self.model(x, cond, t, returns, force_dropout=True)
             epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
+        elif self.skill_condition:
+            epsilon_cond = self.model(x, cond, t, skills, use_dropout=False)
+            epsilon_uncond = self.model(x, cond, t, skills, force_dropout=True)
+            epsilon = epsilon_uncond + self.condition_guidance_w*(epsilon_cond - epsilon_uncond)
         else:
             epsilon = self.model(x, cond, t)
 
diff --git a/code/diffuser/models/helpers.py b/code/diffuser/models/helpers.py
index 53859d4..11ad5d4 100644
--- a/code/diffuser/models/helpers.py
+++ b/code/diffuser/models/helpers.py
@@ -114,6 +114,7 @@ class WeightedLoss(nn.Module):
         loss = self._loss(pred, targ)
         weighted_loss = (loss * self.weights).mean()
         a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()
+        
         return weighted_loss, {'a0_loss': a0_loss}
 
 class WeightedStateLoss(nn.Module):
diff --git a/code/diffuser/models/temporal.py b/code/diffuser/models/temporal.py
index 63155c2..2e093b4 100644
--- a/code/diffuser/models/temporal.py
+++ b/code/diffuser/models/temporal.py
@@ -12,6 +12,17 @@ from .helpers import (
     Upsample1d,
     Conv1dBlock,
 )
+class LayerNorm(nn.Module):
+    def __init__(self, dim, eps = 1e-5):
+        super().__init__()
+        self.eps = eps
+        self.g = nn.Parameter(torch.ones(1, dim, 1))
+        self.b = nn.Parameter(torch.zeros(1, dim, 1))
+
+    def forward(self, x):
+        var = torch.var(x, dim=1, unbiased=False, keepdim=True)
+        mean = torch.mean(x, dim=1, keepdim=True)
+        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class Residual(nn.Module):
     def __init__(self, fn):
@@ -30,25 +41,55 @@ class PreNorm(nn.Module):
     def forward(self, x):
         x = self.norm(x)
         return self.fn(x)
+    
+class PreNormAtt(nn.Module):
+    def __init__(self, dim, fn):
+        super().__init__()
+        self.fn = fn
+        self.norm = LayerNorm(dim)
+
+    def forward(self, x):
+        x = self.norm(x)
+        return self.fn(x)
+
+# class LinearAttention(nn.Module):
+#     def __init__(self, dim, heads = 4, dim_head = 128):
+#         super().__init__()
+#         self.heads = heads
+#         hidden_dim = dim_head * heads
+#         self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
+#         self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+
+#     def forward(self, x):
+#         b, c, h, w = x.shape
+#         qkv = self.to_qkv(x)
+#         q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
+#         k = k.softmax(dim=-1)
+#         context = torch.einsum('bhdn,bhen->bhde', k, v)
+#         out = torch.einsum('bhde,bhdn->bhen', context, q)
+#         out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
+#         return self.to_out(out)
 
 class LinearAttention(nn.Module):
-    def __init__(self, dim, heads = 4, dim_head = 128):
+    def __init__(self, dim, heads=4, dim_head=32):
         super().__init__()
+        self.scale = dim_head ** -0.5
         self.heads = heads
         hidden_dim = dim_head * heads
-        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)
-        self.to_out = nn.Conv2d(hidden_dim, dim, 1)
+        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)
+        self.to_out = nn.Conv1d(hidden_dim, dim, 1)
 
     def forward(self, x):
-        b, c, h, w = x.shape
-        qkv = self.to_qkv(x)
-        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)
-        k = k.softmax(dim=-1)
-        context = torch.einsum('bhdn,bhen->bhde', k, v)
-        out = torch.einsum('bhde,bhdn->bhen', context, q)
-        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)
-        return self.to_out(out)
+        qkv = self.to_qkv(x).chunk(3, dim = 1)
+        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)
+        q = q * self.scale
 
+        k = k.softmax(dim = -1)
+        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)
+
+        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)
+        out = einops.rearrange(out, 'b h c d -> b (h c) d')
+        return self.to_out(out)
 
 class GlobalMixing(nn.Module):
     def __init__(self, dim, heads = 4, dim_head = 128):
@@ -103,7 +144,6 @@ class ResidualTemporalBlock(nn.Module):
         out = self.blocks[1](out)
 
         return out + self.residual_conv(x)
-
 class TemporalUnet(nn.Module):
 
     def __init__(
@@ -112,18 +152,19 @@ class TemporalUnet(nn.Module):
         transition_dim,
         cond_dim,
         dim=128,
-        dim_mults=(1, 2, 4, 8),
+        dim_mults=(1, 4, 8),
         returns_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
         kernel_size=5,
+        skills_condition=False,
+        attention=False,
+        goal_condition=False,
     ):
         super().__init__()
-
         dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
         in_out = list(zip(dims[:-1], dims[1:]))
         print(f'[ models/temporal ] Channel dimensions: {in_out}')
-
         if calc_energy:
             mish = False
             act_fn = nn.SiLU()
@@ -133,7 +174,9 @@ class TemporalUnet(nn.Module):
 
         self.time_dim = dim
         self.returns_dim = dim
-
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.goal_condition = goal_condition
         self.time_mlp = nn.Sequential(
             SinusoidalPosEmb(dim),
             nn.Linear(dim, dim * 4),
@@ -155,6 +198,26 @@ class TemporalUnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.goal_condition:
+            self.goals_mlp = nn.Sequential(
+                        nn.Linear(3, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -196,7 +259,7 @@ class TemporalUnet(nn.Module):
             nn.Conv1d(dim, transition_dim, 1),
         )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None,goals=None,use_dropout=True, force_dropout=False):
         '''
             x : [ batch x horizon x transition ]
             returns : [batch x horizon]
@@ -217,7 +280,24 @@ class TemporalUnet(nn.Module):
             if force_dropout:
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
-
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        elif self.goal_condition:
+            assert goals is not None
+            goals_embed = self.goals_mlp(goals)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(goals_embed.size(0), 1)).to(goals_embed.device)
+                goals_embed = mask*goals_embed
+            if force_dropout:
+                goals_embed = 0*goals_embed
+            t = torch.cat([t, goals_embed], dim=-1)
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -230,6 +310,64 @@ class TemporalUnet(nn.Module):
         x = self.mid_block2(x, t)
 
         # import pdb; pdb.set_trace()
+        for  resnet, resnet2, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
+        if self.calc_energy:
+            # Energy function
+            energy = ((x - x_inp)**2).mean()
+            grad = torch.autograd.grad(outputs=energy, inputs=x_inp, create_graph=True)
+            return grad[0]
+        else:
+            return x
+
+    def get_pred(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
+        h = []
+
+        for resnet, resnet2, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_block2(x, t)
 
         for resnet, resnet2, upsample in self.ups:
             x = torch.cat((x, h.pop()), dim=1)
@@ -241,6 +379,170 @@ class TemporalUnet(nn.Module):
 
         x = einops.rearrange(x, 'b t h -> b h t')
 
+        return x
+
+class TemporalUnetAtt(nn.Module):
+
+    def __init__(
+        self,
+        horizon,
+        transition_dim,
+        cond_dim,
+        dim=128,
+        dim_mults=(1, 4, 8),
+        returns_condition=False,
+        condition_dropout=0.1,
+        calc_energy=False,
+        kernel_size=5,
+        skills_condition=False,
+        attention=False,
+    ):
+        super().__init__()
+        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]
+        in_out = list(zip(dims[:-1], dims[1:]))
+        print(f'[ models/temporal ] Channel dimensions: {in_out}')
+        if calc_energy:
+            mish = False
+            act_fn = nn.SiLU()
+        else:
+            mish = True
+            act_fn = nn.Mish()
+
+        self.time_dim = dim
+        self.returns_dim = dim
+        self.skill_dim = dim
+        self.skill_condition = skills_condition
+        self.time_mlp = nn.Sequential(
+            SinusoidalPosEmb(dim),
+            nn.Linear(dim, dim * 4),
+            act_fn,
+            nn.Linear(dim * 4, dim),
+        )
+
+        self.returns_condition = returns_condition
+        self.condition_dropout = condition_dropout
+        self.calc_energy = calc_energy
+
+        if self.returns_condition:
+            self.returns_mlp = nn.Sequential(
+                        nn.Linear(1, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),        
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
+        else:
+            embed_dim = dim
+
+        self.downs = nn.ModuleList([])
+        self.ups = nn.ModuleList([])
+        num_resolutions = len(in_out)
+
+        print(in_out)
+        for ind, (dim_in, dim_out) in enumerate(in_out):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.downs.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_in, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_out, dim_out, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),
+                Downsample1d(dim_out) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon // 2
+
+        mid_dim = dims[-1]
+        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+        self.mid_attn = Residual(PreNormAtt(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()
+        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish)
+
+        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
+            is_last = ind >= (num_resolutions - 1)
+
+            self.ups.append(nn.ModuleList([
+                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                ResidualTemporalBlock(dim_in, dim_in, embed_dim=embed_dim, horizon=horizon, kernel_size=kernel_size, mish=mish),
+                Residual(PreNormAtt(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),
+                Upsample1d(dim_in) if not is_last else nn.Identity()
+            ]))
+
+            if not is_last:
+                horizon = horizon * 2
+
+        self.final_conv = nn.Sequential(
+            Conv1dBlock(dim, dim, kernel_size=kernel_size, mish=mish),
+            nn.Conv1d(dim, transition_dim, 1),
+        )
+
+    def forward(self, x, cond, time, returns=None, skills=None,use_dropout=True, force_dropout=False):
+        '''
+            x : [ batch x horizon x transition ]
+            returns : [batch x horizon]
+        '''
+        if self.calc_energy:
+            x_inp = x
+
+        x = einops.rearrange(x, 'b h t -> b t h')
+
+        t = self.time_mlp(time)
+
+        if self.returns_condition:
+            assert returns is not None
+            returns_embed = self.returns_mlp(returns)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(returns_embed.size(0), 1)).to(returns_embed.device)
+                returns_embed = mask*returns_embed
+            if force_dropout:
+                returns_embed = 0*returns_embed
+            t = torch.cat([t, returns_embed], dim=-1)
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+        h = []
+
+        for resnet, resnet2, attn, downsample in self.downs:
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            h.append(x)
+            x = downsample(x)
+
+        x = self.mid_block1(x, t)
+        x = self.mid_attn(x)
+        x = self.mid_block2(x, t)
+
+        # import pdb; pdb.set_trace()
+        for  resnet, resnet2, attn, upsample in self.ups:
+            h_1 = h.pop()
+            x = torch.cat((x, h_1), dim=1)
+            x = resnet(x, t)
+            x = resnet2(x, t)
+            x = attn(x)
+            x = upsample(x)
+
+        x = self.final_conv(x)
+
+        x = einops.rearrange(x, 'b t h -> b h t')
+
         if self.calc_energy:
             # Energy function
             energy = ((x - x_inp)**2).mean()
@@ -268,6 +570,16 @@ class TemporalUnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         h = []
 
         for resnet, resnet2, downsample in self.downs:
@@ -300,6 +612,7 @@ class MLPnet(nn.Module):
         dim_mults=(1, 2, 4, 8),
         horizon=1,
         returns_condition=True,
+        skill_condition=False,
         condition_dropout=0.1,
         calc_energy=False,
     ):
@@ -321,6 +634,7 @@ class MLPnet(nn.Module):
         )
 
         self.returns_condition = returns_condition
+        self.skill_condition = skill_condition
         self.condition_dropout = condition_dropout
         self.calc_energy = calc_energy
         self.transition_dim = transition_dim
@@ -336,6 +650,16 @@ class MLPnet(nn.Module):
                     )
             self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
             embed_dim = 2*dim
+        elif self.skill_condition:
+            self.skills_mlp = nn.Sequential(
+                        nn.Linear(2, dim),
+                        act_fn,
+                        nn.Linear(dim, dim * 4),
+                        act_fn,
+                        nn.Linear(dim * 4, dim),
+                    )
+            self.mask_dist = Bernoulli(probs=1-self.condition_dropout)
+            embed_dim = 2*dim
         else:
             embed_dim = dim
 
@@ -347,7 +671,7 @@ class MLPnet(nn.Module):
                         nn.Linear(1024, self.action_dim),
                     )
 
-    def forward(self, x, cond, time, returns=None, use_dropout=True, force_dropout=False):
+    def forward(self, x, cond, time, returns=None, skills=None, use_dropout=True, force_dropout=False):
         '''
             x : [ batch x action ]
             cond: [batch x state]
@@ -366,6 +690,17 @@ class MLPnet(nn.Module):
                 returns_embed = 0*returns_embed
             t = torch.cat([t, returns_embed], dim=-1)
 
+        
+        elif self.skill_condition:
+            assert skills is not None
+            skills_embed = self.skills_mlp(skills)
+            if use_dropout:
+                mask = self.mask_dist.sample(sample_shape=(skills_embed.size(0), 1)).to(skills_embed.device)
+                skills_embed = mask*skills_embed
+            if force_dropout:
+                skills_embed = 0*skills_embed
+            t = torch.cat([t, skills_embed], dim=-1)
+
         inp = torch.cat([t, cond, x], dim=-1)
         out  = self.mlp(inp)
 
diff --git a/code/diffuser/utils/rendering.py b/code/diffuser/utils/rendering.py
index 8fd5873..da4304f 100644
--- a/code/diffuser/utils/rendering.py
+++ b/code/diffuser/utils/rendering.py
@@ -5,7 +5,9 @@ import imageio
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap
 import gym
-import mujoco_py as mjc
+import gymnasium as gym
+import panda_gym
+#import mujoco_py as mjc
 import warnings
 import pdb
 
@@ -66,11 +68,11 @@ class MuJoCoRenderer:
         ## @TODO : clean up
         self.observation_dim = np.prod(self.env.observation_space.shape) - 1
         self.action_dim = np.prod(self.env.action_space.shape)
-        try:
-            self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
-        except:
-            print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
-            self.viewer = None
+        # try:
+        #     self.viewer = mjc.MjRenderContextOffscreen(self.env.sim)
+        # except:
+        #     print('[ utils/rendering ] Warning: could not initialize offscreen renderer')
+        #     self.viewer = None
 
     def pad_observation(self, observation):
         state = np.concatenate([
diff --git a/code/diffuser/utils/training.py b/code/diffuser/utils/training.py
index e8dcdb4..2d1cfe1 100644
--- a/code/diffuser/utils/training.py
+++ b/code/diffuser/utils/training.py
@@ -6,7 +6,8 @@ import einops
 import pdb
 import diffuser
 from copy import deepcopy
-
+#from scripts.eval_parallel import eval_diffusion
+from scripts.evaluate_panda_parallel import eval_diffusion
 from .arrays import batch_to_device, to_np, to_device, apply_dict
 from .timer import Timer
 from .cloud import sync_logs
@@ -51,11 +52,15 @@ class Trainer(object):
         sample_freq=1000,
         save_freq=1000,
         label_freq=100000,
+        test_freq = 20000,
         save_parallel=False,
         n_reference=8,
         bucket=None,
         train_device='cuda',
-        save_checkpoints=False,
+        save_checkpoints=True,
+        wandb = None,
+        config = None,
+
     ):
         super().__init__()
         self.model = diffusion_model
@@ -63,21 +68,21 @@ class Trainer(object):
         self.ema_model = copy.deepcopy(self.model)
         self.update_ema_every = update_ema_every
         self.save_checkpoints = save_checkpoints
-
+        self.wandb = wandb
         self.step_start_ema = step_start_ema
         self.log_freq = log_freq
         self.sample_freq = sample_freq
         self.save_freq = save_freq
         self.label_freq = label_freq
         self.save_parallel = save_parallel
-
+        self.test_freq = test_freq
         self.batch_size = train_batch_size
         self.gradient_accumulate_every = gradient_accumulate_every
-
+        self.config = config
         self.dataset = dataset
 
         self.dataloader = cycle(torch.utils.data.DataLoader(
-            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True
+            self.dataset, batch_size=train_batch_size, num_workers=0, shuffle=True, pin_memory=True,
         ))
         self.dataloader_vis = cycle(torch.utils.data.DataLoader(
             self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True
@@ -126,24 +131,34 @@ class Trainer(object):
             if self.step % self.save_freq == 0:
                 self.save()
 
+            # if self.step % self.test_freq == 0:
+            #     success_rate, rewards =eval_diffusion(self.ema_model, self.dataset,self.config)
+            #     log = {}
+            #     log["success_rate"]  = success_rate
+            #     log["rewards"] = rewards
+            #     self.wandb.log(log)
+
             if self.step % self.log_freq == 0:
                 infos_str = ' | '.join([f'{key}: {val:8.4f}' for key, val in infos.items()])
                 logger.print(f'{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}')
                 metrics = {k:v.detach().item() for k, v in infos.items()}
                 metrics['steps'] = self.step
                 metrics['loss'] = loss.detach().item()
+                if self.wandb is not None:
+                    self.wandb.log(metrics)
+                
                 logger.log_metrics_summary(metrics, default_stats='mean')
 
-            if self.step == 0 and self.sample_freq:
-                self.render_reference(self.n_reference)
+            #if self.step == 0 and self.sample_freq:
+                #self.render_reference(self.n_reference)
 
-            if self.sample_freq and self.step % self.sample_freq == 0:
-                if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
-                    self.inv_render_samples()
-                elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
-                    pass
-                else:
-                    self.render_samples()
+            # if self.sample_freq and self.step % self.sample_freq == 0:
+            #     if self.model.__class__ == diffuser.models.diffusion.GaussianInvDynDiffusion:
+            #         self.inv_render_samples()
+            #     elif self.model.__class__ == diffuser.models.diffusion.ActionGaussianDiffusion:
+            #         pass
+            #     # else:
+            #     #     self.render_samples()
 
             self.step += 1
 
diff --git a/code/scripts/evaluate_inv_parallel.py b/code/scripts/evaluate_inv_parallel.py
index a7e019f..47369aa 100644
--- a/code/scripts/evaluate_inv_parallel.py
+++ b/code/scripts/evaluate_inv_parallel.py
@@ -38,6 +38,7 @@ def evaluate(**deps):
 
     # Load configs
     torch.backends.cudnn.benchmark = True
+    Config.seed = 1234567
     utils.set_seed(Config.seed)
 
     dataset_config = utils.Config(
@@ -60,7 +61,7 @@ def evaluate(**deps):
     )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
 
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
@@ -121,7 +122,7 @@ def evaluate(**deps):
 
     model = model_config()
     diffusion = diffusion_config(model)
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None)
     logger.print(utils.report_parameters(model), color='green')
     trainer.step = state_dict['step']
     trainer.model.load_state_dict(state_dict['model'])
@@ -155,14 +156,15 @@ def evaluate(**deps):
 
         action = dataset.normalizer.unnormalize(action, 'actions')
 
-        if t == 0:
-            normed_observations = samples[:, :, :]
-            observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
-            savepath = os.path.join('images', 'sample-planned.png')
-            renderer.composite(savepath, observations)
+        # if t == 0:
+        #     normed_observations = samples[:, :, :]
+        #     observations = dataset.normalizer.unnormalize(normed_observations, 'observations')
+        #     savepath = os.path.join('images', 'sample-planned.png')
+        #     renderer.composite(savepath, observations)
 
         obs_list = []
         for i in range(num_eval):
+            print(f"action: {action[i]}")
             this_obs, this_reward, this_done, _ = env_list[i].step(action[i])
             obs_list.append(this_obs[None])
             if this_done:
@@ -180,12 +182,15 @@ def evaluate(**deps):
 
         obs = np.concatenate(obs_list, axis=0)
         recorded_obs.append(deepcopy(obs[:, None]))
+        print(f"t: {t}, episode_rewards: {episode_rewards}, dones: {dones}")
+        if t> 200:
+            break
         t += 1
 
     recorded_obs = np.concatenate(recorded_obs, axis=1)
-    savepath = os.path.join('images', f'sample-executed.png')
-    renderer.composite(savepath, recorded_obs)
-    episode_rewards = np.array(episode_rewards)
+    # savepath = os.path.join('images', f'sample-executed.png')
+    # renderer.composite(savepath, recorded_obs)
+    # episode_rewards = np.array(episode_rewards)
 
     logger.print(f"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}", color='green')
     logger.log_metrics_summary({'average_ep_reward':np.mean(episode_rewards), 'std_ep_reward':np.std(episode_rewards)})
diff --git a/code/scripts/train.py b/code/scripts/train.py
index db05e5a..c5a1e55 100644
--- a/code/scripts/train.py
+++ b/code/scripts/train.py
@@ -1,13 +1,12 @@
 import diffuser.utils as utils
 import torch
-
+import wandb
 def main(**deps):
     from ml_logger import logger, RUN
     from config.locomotion_config import Config
-
+    
     RUN._update(deps)
     Config._update(deps)
-
     # logger.remove('*.pkl')
     # logger.remove("traceback.err")
     logger.log_params(Config=vars(Config), RUN=vars(RUN))
@@ -21,10 +20,21 @@ def main(**deps):
 
     torch.backends.cudnn.benchmark = True
     utils.set_seed(Config.seed)
+    Config.device = "cuda:6"
+    wandb.init(
+    # set the wandb project where this run will be logged
+        project=Config.wandb_project,
+        entity=Config.wandb_entity,
+        group=Config.wandb_group,
+        name=Config.wandb_name,
+        # track hyperparameters and run metadata
+        config=Config.__dict__
+    )
+
     # -----------------------------------------------------------------------------#
     # ---------------------------------- dataset ----------------------------------#
     # -----------------------------------------------------------------------------#
-
+    print("Dataset: ", Config.dataset)
     dataset_config = utils.Config(
         Config.loader,
         savepath='dataset_config.pkl',
@@ -38,23 +48,25 @@ def main(**deps):
         returns_scale=Config.returns_scale,
         discount=Config.discount,
         termination_penalty=Config.termination_penalty,
+        max_n_episodes=Config.max_n_episodes,
+        skill_dataset=Config.skill_dataset,
     )
 
-    render_config = utils.Config(
-        Config.renderer,
-        savepath='render_config.pkl',
-        env=Config.dataset,
-    )
+    # render_config = utils.Config(
+    #     Config.renderer,
+    #     savepath='render_config.pkl',
+    #     env=Config.dataset,
+    # )
 
     dataset = dataset_config()
-    renderer = render_config()
+    #renderer = render_config()
     observation_dim = dataset.observation_dim
     action_dim = dataset.action_dim
 
     # -----------------------------------------------------------------------------#
     # ------------------------------ model & trainer ------------------------------#
     # -----------------------------------------------------------------------------#
-    if Config.diffusion == 'models.GaussianInvDynDiffusion':
+    if Config.diffusion == 'models.GaussianInvDynDiffusion' or Config.diffusion == 'models.GaussianInvDynDiffusionSkills':
         model_config = utils.Config(
             Config.model,
             savepath='model_config.pkl',
@@ -63,10 +75,12 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
             device=Config.device,
+            attention=Config.attention,
         )
 
         diffusion_config = utils.Config(
@@ -87,7 +101,9 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
+            goal_condition=Config.goal_condition,
             device=Config.device,
         )
     else:
@@ -99,6 +115,7 @@ def main(**deps):
             cond_dim=observation_dim,
             dim_mults=Config.dim_mults,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             dim=Config.dim,
             condition_dropout=Config.condition_dropout,
             calc_energy=Config.calc_energy,
@@ -120,6 +137,7 @@ def main(**deps):
             loss_weights=Config.loss_weights,
             loss_discount=Config.loss_discount,
             returns_condition=Config.returns_condition,
+            skills_condition=Config.skills_condition,
             condition_guidance_w=Config.condition_guidance_w,
             device=Config.device,
         )
@@ -140,6 +158,8 @@ def main(**deps):
         n_reference=Config.n_reference,
         train_device=Config.device,
         save_checkpoints=Config.save_checkpoints,
+        config=Config.__dict__,
+        
     )
 
     # -----------------------------------------------------------------------------#
@@ -150,7 +170,7 @@ def main(**deps):
 
     diffusion = diffusion_config(model)
 
-    trainer = trainer_config(diffusion, dataset, renderer)
+    trainer = trainer_config(diffusion, dataset, None,wandb=wandb)
 
     # -----------------------------------------------------------------------------#
     # ------------------------ test forward & backward pass -----------------------#
@@ -163,7 +183,6 @@ def main(**deps):
     loss, _ = diffusion.loss(*batch)
     loss.backward()
     logger.print('')
-
     # -----------------------------------------------------------------------------#
     # --------------------------------- main loop ---------------------------------#
     # -----------------------------------------------------------------------------#